{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "221a1761-d8ae-413b-846c-538db769cd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/10 16:46:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark y MLflow listos para escalar.\n"
     ]
    }
   ],
   "source": [
    "# Inicializaci贸n en Python\n",
    "from pyspark.sql import SparkSession\n",
    "import mlflow\n",
    "import mlflow.spark # Importante para loggear modelos de Spark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# 1. Iniciar Spark (Driver Program)\n",
    "spark = SparkSession.builder.appName(\"MLOpsSparkML\")     .getOrCreate()\n",
    "\n",
    "# 2. Configurar MLflow Tracking (Ejemplo local en un directorio)\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "# 3. Definir el experimento activo\n",
    "mlflow.set_experiment(\"Clasificacion_Ventas_Inicial\")\n",
    "\n",
    "print(\"Spark y MLflow listos para escalar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "514a8ff7-e09b-473c-b11e-685b1fa7fe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Ejemplo 1: Pipeline Completo ---\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# --- Ejemplo 1: Pipeline Completo (Estimators) + Log con MLflow ---\n",
    "# -----------------------------------------------------------------\n",
    "print(\"\\n--- Iniciando Ejemplo 1: Pipeline Completo ---\")\n",
    "\n",
    "# 4. Crear datos de ejemplo\n",
    "# Queremos predecir si un cliente comprar谩 (label)\n",
    "# basado en su departamento (categ贸rico) y edad (num茅rico).\n",
    "datos_entrenamiento = [\n",
    "    (0, \"Ventas\", 30, 1),  # id, depto, edad, si_compra (label=1)\n",
    "    (1, \"IT\", 45, 1),\n",
    "    (2, \"Ventas\", 22, 0),  # no_compra (label=0)\n",
    "    (3, \"Mktg\", 38, 0),\n",
    "    (4, \"IT\", 51, 1),\n",
    "    (5, \"Mktg\", 29, 1),\n",
    "    (6, \"Ventas\", 40, 0),\n",
    "    (7, \"IT\", 33, 1)\n",
    "]\n",
    "\n",
    "columnas = [\"id\", \"departamento\", \"edad\", \"label\"]\n",
    "df_train = spark.createDataFrame(datos_entrenamiento, columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e1a7e4-15ab-4e19-88a9-c71c6fed9b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----+-----+\n",
      "| id|departamento|edad|label|\n",
      "+---+------------+----+-----+\n",
      "|  0|      Ventas|  30|    1|\n",
      "|  1|          IT|  45|    1|\n",
      "|  2|      Ventas|  22|    0|\n",
      "|  3|        Mktg|  38|    0|\n",
      "|  4|          IT|  51|    1|\n",
      "|  5|        Mktg|  29|    1|\n",
      "|  6|      Ventas|  40|    0|\n",
      "|  7|          IT|  33|    1|\n",
      "+---+------------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecc1cf8f-1f6e-42b0-916f-925a9d8fbd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorAssembler_22c247c7f1e0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 5. Definir la Pipeline (una secuencia de Estimators y Transformers)\n",
    "\n",
    "# --- Etapas de Preprocesamiento (Estimators) ---\n",
    "# Un Estimator debe \"aprender\" de los datos (.fit())\n",
    "\n",
    "# Estimator 1: Aprende el mapeo de strings a n煤meros (ej. \"Ventas\"->0.0, \"IT\"->1.0)\n",
    "indexer = StringIndexer(inputCol=\"departamento\", outputCol=\"depto_idx\",handleInvalid='keep')\n",
    "\n",
    "# Estimator 2: Aprende a convertir esos n煤meros en vectores one-hot\n",
    "encoder = OneHotEncoder(inputCol=\"depto_idx\", outputCol=\"depto_vec\")\n",
    "\n",
    "\n",
    "# --- Etapa de Ensamblaje (Transformer) ---\n",
    "# Un Transformer solo aplica una regla fija (.transform())\n",
    "\n",
    "# Transformer: Ensambla las columnas de features en un solo vector.\n",
    "# No \"aprende\" nada, solo sigue la instrucci贸n de juntar.\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"depto_vec\", \"edad\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b717fd6-2387-4cce-a647-6fb731f26988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Run de MLflow: 4be6e63afa484e689f3aa3ecc8379efb\n",
      "Modelo entrenado (PipelineModel creado).\n",
      "M茅trica (AUC): 0.8666666666666667\n",
      "Modelo y m茅tricas registradas en MLflow (Run ID: 4be6e63afa484e689f3aa3ecc8379efb)\n",
      " View run peaceful-bug-423 at: http://localhost:5000/#/experiments/1/runs/4be6e63afa484e689f3aa3ecc8379efb\n",
      "И View experiment at: http://localhost:5000/#/experiments/1\n",
      "\n",
      "--- Cargando modelo desde MLflow para predicci贸n ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 17:20:47 INFO mlflow.spark: URI 'runs:/4be6e63afa484e689f3aa3ecc8379efb/modelo-clasificacion-ventas/sparkml' does not point to the current DFS.\n",
      "2025/11/10 17:20:47 INFO mlflow.spark: File 'runs:/4be6e63afa484e689f3aa3ecc8379efb/modelo-clasificacion-ventas/sparkml' not found on DFS. Will attempt to upload the file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----+----------+\n",
      "| id|departamento|edad|prediction|\n",
      "+---+------------+----+----------+\n",
      "| 10|          IT|  33|       1.0|\n",
      "| 11|       Datos|  48|       1.0|\n",
      "| 12|        Mktg|  21|       1.0|\n",
      "+---+------------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Etapa del Modelo (Estimator) ---\n",
    "# El Estimator principal: El algoritmo de Machine Learning\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "\n",
    "# 6. Encapsular todo en una Pipeline\n",
    "# Una Pipeline es un \"Estimator\" grande que contiene otras etapas.\n",
    "pipeline = Pipeline(stages=[indexer, encoder, assembler, lr])\n",
    "\n",
    "# 7.  Entrenar y Registrar el Modelo con MLflow\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"Iniciando Run de MLflow: {run.info.run_id}\")\n",
    "\n",
    "    # --- El coraz贸n del proceso: .fit() ---\n",
    "    # Al llamar a .fit() en la Pipeline (un Estimator):\n",
    "    # 1. Se llama a .fit() en 'indexer' -> Se crea un 'StringIndexerModel' (Transformer)\n",
    "    # 2. Se llama a .fit() en 'encoder' -> Se crea un 'OneHotEncoderModel' (Transformer)\n",
    "    # 3. Se llama a .transform() en 'assembler' (ya es Transformer)\n",
    "    # 4. Se llama a .fit() en 'lr' -> Se crea un 'LogisticRegressionModel' (Transformer)\n",
    "    \n",
    "    # El resultado es un \"PipelineModel\", que es un TRANSFORMER.\n",
    "    pipeline_model = pipeline.fit(df_train)\n",
    "    print(\"Modelo entrenado (PipelineModel creado).\")\n",
    "\n",
    "    # 8.  Registrar el modelo (el Transformer) en MLflow\n",
    "    # MLflow sabe c贸mo guardar, serializar y versionar modelos de Spark.\n",
    "    mlflow.spark.log_model(\n",
    "        spark_model=pipeline_model,\n",
    "        artifact_path=\"modelo-clasificacion-ventas\"\n",
    "    )\n",
    "\n",
    "    # Registrar par谩metros\n",
    "    mlflow.log_param(\"max_iter_lr\", 10)\n",
    "    mlflow.log_param(\"total_etapas\", len(pipeline.getStages()))\n",
    "    \n",
    "    # Evaluar el modelo y registrar m茅tricas\n",
    "    predicciones_train = pipeline_model.transform(df_train)\n",
    "    evaluador = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "\n",
    "\n",
    "    auc = evaluador.evaluate(predicciones_train)\n",
    "    evaluador_pr=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderPR\")\n",
    "    auc_pr = evaluador_pr.evaluate(predicciones_train)\n",
    "    mlflow.log_metric(\"auc_entrenamiento\", auc)\n",
    "    mlflow.log_metric(\"auc_pr\",auc_pr)\n",
    "    \n",
    "    print(f\"M茅trica (AUC): {auc}\")\n",
    "    print(f\"Modelo y m茅tricas registradas en MLflow (Run ID: {run.info.run_id})\")\n",
    "\n",
    "# 9.  Usar el Modelo (Transformer) cargado desde MLflow para Inferencia\n",
    "print(\"\\n--- Cargando modelo desde MLflow para predicci贸n ---\")\n",
    "\n",
    "# Simular datos nuevos (sin la columna \"label\")\n",
    "datos_nuevos = [\n",
    "    (10, \"IT\", 33),     # Un IT de 33 a帽os\n",
    "    (11, \"Datos\", 48), # Un Ventas de 48\n",
    "    (12, \"Mktg\", 21)    # Un Mktg de 21\n",
    "]\n",
    "df_nuevos = spark.createDataFrame(datos_nuevos, [\"id\", \"departamento\", \"edad\"])\n",
    "\n",
    "# Cargar el PipelineModel (Transformer) guardado\n",
    "modelo_cargado = mlflow.spark.load_model(\n",
    "    f\"runs:/{run.info.run_id}/modelo-clasificacion-ventas\"\n",
    ")\n",
    "\n",
    "# Aplicar la transformaci贸n (predicci贸n)\n",
    "# Llama a .transform() en todas las etapas del PipelineModel\n",
    "predicciones_nuevas = modelo_cargado.transform(df_nuevos)\n",
    "\n",
    "predicciones_nuevas.select(\"id\", \"departamento\", \"edad\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fb23ed1-46bc-41d9-a28c-e8aa88b70e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "5      1\n",
       "6      0\n",
       "7      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_train.select(\"label\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "024840fb-1043-415c-be43-cacb8d395f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexerModel: uid=StringIndexer_93fad8badc3d, handleInvalid=keep,\n",
       " OneHotEncoderModel: uid=OneHotEncoder_3f8af90075e4, dropLast=true, handleInvalid=error,\n",
       " VectorAssembler_91ae1be3bee4,\n",
       " LogisticRegressionModel: uid=LogisticRegression_dc0089b308da, numClasses=2, numFeatures=4]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6bcf7c-fdf4-48ad-bfb6-c1e4e32d59d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
